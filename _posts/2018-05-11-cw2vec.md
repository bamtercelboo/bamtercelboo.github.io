---
layout:     post
title:      "cw2vec理论及其实现"
date:       2018-05-11
author:     "bamtercelboo"
header-img: "img/post-bg-2015.jpg"
tags:
    - cw2vec
    - word2vec
    - Word Embedding
    - c++

---


#  导读  #

本文对AAAI 2018(Association for the Advancement of Artificial Intelligence 2018)高分录用的一篇中文词向量论文（[cw2vec: Learning Chinese Word Embeddings
with Stroke n-gram Information](http://www.statnlp.org/wp-content/uploads/papers/2018/cw2vec/cw2vec.pdf)）进行简述与实现，这篇论文出自蚂蚁金服人工智能部。本文将从背景知识、模型简介、c++实现、实验结果、结论等几个方面来进行阐述。

# 一、背景知识 #

目前已经存在很多的词向量模型，但是较多的词向量模型都是基于西方语言，像英语，西班牙语，德语等，这些西方语言的内部组成都是拉丁字母，然而，由于中文书写和西方语言完全不同，中文词语包含很少的中文字符，但是中文字符内部包含了很强的语义信息，如何利用中文字符内部的语义信息来训练词向量，针对中文字符的特点，近些年来，有越来越多的研究者提出了各种各样的中文词向量模型。  

通过观察中文字符内部组成，发现中文字符包含偏旁部首、字符组件，笔画信息等语义信息特征（如下图），基于偏旁部首和汉字组件特征的中文词向量模型已经有人提出，并取得了较好的效果。  
![](https://i.imgur.com/qrCb8to.jpg)  

本篇论文采用笔画信息作为特征，由于每个字符包含很多的笔画，类似于一个英文单词包含很多的拉丁字母，在这个基础之上，提出了笔画的n-gram特征。这个思想来源于2016年facebook提出的论文（[Enriching Word Vectors with Subword Information](https://arxiv.org/pdf/1607.04606.pdf)），目前facebook这篇论文已经被引用300多次，影响力很大，cw2vec可以称之为中文版本的fasttext。

# 二、模型简介 #

#### 1、 词语分割 ####

把中文词语分割为单个字符，为了获取中文字符的笔画信息
> 词语：大人  分割为：（1）大 （2）人    

#### 2、 笔画特征 ####

获取中文字符的笔画信息
> 大： 一ノ丶   
> 人： ノ丶

获取词语的笔画信息
> 大人： 一ノ丶 ノ丶


#### 3、 笔画特征数字化 ####

为了方便，论文提及把笔画信息数字化，用数字代表每一种笔画信息，如下图。  
![](https://i.imgur.com/gx44sVQ.jpg)  
那么“大人”这个词的笔画信息就可以表示为：
> 大人： 一ノ丶 ノ丶  
> 大人：13434
  
我从训练语料中获取到13354个汉字，并获取笔画信息，统计笔画种类和上图一致，只有5种笔画信息。  

#### 4、 N元笔画特征 ####
提取n-gram笔画特征
> 3-gram：134、343、434  
> 4-gram：1343、3434  
> 5-gram：13434  
> ......

上述4个步骤，如下图：  
![](https://i.imgur.com/oYE08t5.jpg)

#### 5、cw2vec模型  ####
word2vec提出了CBOW和Skip-Gram两个模型（[详解](https://bamtercelboo.github.io/2018/03/24/word2vec/)），cw2vec在Skip-Gram基础之上进行改进，把**词语的n-gram笔画特征信息代替词语**进行训练，cw2vec模型如下图。    
> 短语：治理 雾霾 刻不容缓  
> 中心词：雾霾  
> 上下文词：治理，刻不容缓

![](https://i.imgur.com/OROhByA.jpg)

论文中提及上下文词向量为最终cw2vec模型的输出词向量。


# 三、c++实现 #

# 四、实验结果 #

# 五、结论 #

# References  #
[1] Cao, Shaosheng, et al. "cw2vec: Learning Chinese Word Embeddings with Stroke n-gram Information." (2018).  
[2] Bojanowski, Piotr, et al. "Enriching word vectors with subword information." arXiv preprint arXiv:1607.04606 (2016).  
[3] 





