---
layout:     post
title:      "中国法研杯 --- 司法人工智能挑战赛"
date:       2018-10-16
author:     "bamtercelboo"
header-img: "img/post-bg-2015.jpg"
tags:
    - CAIL2018
    - 中国法研杯-司法人工智能挑战赛
    - Law

---


#  一、导读  #

![](https://i.imgur.com/JPDyps9.jpg)  

前段时间参加了`中国法研杯---司法人工智能挑战赛（CAIL2018）`，这个比赛是为了促进法律智能相关技术的发展，在最高人民法院信息中心、共青团中央青年发展部的指导下，中国司法大数据研究院、中国中文信息学会、中电科系统团委联合清华大学、北京大学、中国科学院软件研究所共同举办。  
在参加法研杯分享会的过程中聆听了各个团队的经验分享，有很多值得借鉴和学习的经验，在此对其进行一下梳理，希望对后续的工作有所帮助。

#  二、任务简介  #

任务一 ，`罪名预测`：根据刑事法律文书中的案情描述和事实部分，预测被告人被判的罪名；  
任务二 ，`法条推荐`：根据刑事法律文书中的案情描述和事实部分，预测本案涉及的相关法条；  
任务三 ，`刑期预测`：根据刑事法律文书中的案情描述和事实部分，预测被告人的刑期长短。  
更加详细的`任务简介`，`评价指标`，`数据下载`可以查看 [中国法研杯---人工智能司法比赛](http://cail.cipsc.org.cn/instruction) 和 [thunlp/CAIL](https://github.com/thunlp/CAIL)。

#  三、任务建模  #
各个团队针对任务一（罪名预测）和任务二（法条推荐）的建模方式都采用了`多标签分类`问题来进行建模，然而，针对于任务三（刑期预测），由于刑期范围分布的不平衡且分布范围广，针对刑期预测，可以采用`分类`或者是`回归`的建模方式来提出解决方案。

#  四、数据处理 #

![](https://i.imgur.com/nvUC6fW.jpg)    

上图是一个数据样例，数据属于段落描述，其中包含了时间、地点、人名、金钱、毒品重量等，针对这些，数据处理就格外的重要，数据处理主要的部分包含了以下的几个方面。  
1. `分词`： 面对数据，分词是首先会考虑到的，其中大多数团队采用了jieba分词，虽然还有其他的一些分词模型，但性能方面还是jieba分词的性能要好一些。  
2.   `去除停用词`： 分词的时候去除中文常用的停用词。  
3.   `金额处理`： 数据中包含了很多的金钱，不仅仅包含数字类型的金额，还包含中文汉字的金额。	    
	1.   中文金额的处理可以将其转换数字金额（[脚本](https://github.com/bamtercelboo/corpus_process_script/tree/master/cn_to_arabic)）    
	2.   数字金额的处理方式有很多，`西安电子科技大学`把金额按照区间进行了分类处理，还有把某一区间的金额进行归一化处理等。  
4.   `毒品重量`： 毒品重量和金额一样，分布范围广，可以类似金额一样的处理方式。  
5.   `酒精浓度`： 酒精浓度和毒品重量，金额分布相比，比他们相对小一些，`富驰信息技术有限公司`也对这个进行了区间分类。  
6.   `时间`、`地名`、`人名`： 数据中包含了大量的时间，地名，人名，很多团队都会对这部分进行处理，西安电子科技大学和富驰信息技术有限公司对这部分进行了处理，在他们的验证过程结果中，表明这一部分的处理没有效果或者是效果不是很明显，具体原因可能需要有法律背景的专业人士解答一下。  

#  五、词向量 #
词向量这部分可能是影响很大的，相信很多的团队都尝试过`word2vec`或者是`glove`来训练词向量，但是在词向量这一部分除了word2vec和glove还有其他的训练方式。  
`阿里巴巴达摩院`在这部分尝试的应该是比较多的，他们团队不仅仅在word2vec、glove、`fasttext`（有监督，无监督）上面进行了不同维度，不同的数据源（全部cail2018数据集、维基百科数据、搜狗新闻数据）的尝试，而且在新提出的一个词向量模型(`ELMO`)中进行了尝试，这篇论文是 [Deep contextualized word representations](https://arxiv.org/pdf/1802.05365.pdf)。    
`ELMO模型不仅仅能够学习到词汇用法的复杂性，比如语法、语义，还能够学习不同上下文情况下的词汇多义性`。这次比赛中词向量的训练使用ELMO模型相对于word2vec、glove等有大幅度的提高。不仅仅是阿里巴巴达摩院，还有很多团队都使用了这个模型来做词向量的训练工作。后续会对ELMO详细的看一下。    
在这一部分，富驰信息技术有限公司采用了一个新的简单有效的方法，`使用word2vec和glove同时训练出一个词向量，然后把两份词向量合并在一起，根据他们的实验结果，这种方法要比随机初始化高5%左右`。  


#  六、模型 #
模型这一部分可谓是让我长见识了，各个团队尝试的模型也是不尽其数，像`国双科技`、`富驰信息`、`西安电子科技`、`中电28所`、`达观数据`、`华宇软件`、`汉王数字` 都尝试了很多的模型，大概有`SVM`、`CNN`、`DPCNN`、`RCNN`、`CNN+capsule`、`TextCNN`、`FMCNN`、`BiLSTM`、`BiGRU`、`Dual-LSTM`、`TextRNN`、`HAN`、`LSTM+inception`、`Attention`、`各个模型之间的组合`以及`深度学习与机器学习的融合`等。  

简单的介绍几个：  

- `富驰信息技术`  
针对罪名预测和法条推荐任务，采用了机器学习与深度学习联合的方式。  
机器学习： 使用`Label Powerset`来解决多标签分类问题。  

 ![](https://i.imgur.com/B6FIsuP.jpg)  

深度学习采用的是`TextCNN`、`BiGRU-CNN`、`DUAL-LSTM`来分别训练。  
最后采用的是深度学习与机器学习的整合的最终模型。  

![](https://i.imgur.com/WbUbkNJ.jpg)    

针对刑期预测， 按照区间划分，然后做回归或者是分类（他们的实验结果表明分类的效果要好）。  

- `阿里巴巴达摩院`  

![](https://i.imgur.com/8QwrGNa.jpg)  

达摩院为这个比赛专门量身订做了一个模型，不可谓不复杂。  
针对混淆罪名和小数目在模型中增加了`Arrribute Classifiter`模块。  
针对法条预测，引入了`专家知识`（法条描述）。  
针对刑期预测， 按照区间划分，然后做回归。  

- `国双科技`      

![](https://i.imgur.com/GqdPR8P.jpg)  

在任务一与任务二上面采用了`联合模型`来互相促进。  
对于任务三，采用了`联合模型的特征`与`规则特征`进行GBDT训练。

 
#  七、重点关注 #
各个团队提出的模型都是为了解决任务中的难题，在这个比赛中，存在一些难以解决的问题需要重点关注一下。  

## 数据不平衡问题 ##
数据不平衡问题是各个团队考虑最多的：    

1. 西安电子科技大学针对这个问题采用了`增加损失权重`，`多尺度阈值分类`的策略。
2. 富驰信息技术采用了`上采样`与`下采样`的策略，但是效果并不明显；  从网络上获取相关数据，补充到训练数据中，效果提升比较明显，模型泛化能力不错。  
3. 国双科技采用了`多任务联合学习`来弥补这个缺陷。  
4. 华宇软件采用了`复制小类别的数据`到训练数据，`网络获取相关数据`来增强数据。  

## 易混淆罪名问题 ##
数据中包含了很多类似的罪名，容易混淆，像`抢劫、抢夺与盗窃`这三个，`职务侵占与侵占`等。    
1. 华宇软件给出了的解决方案是`加入要素维度的关键性特征`。  
2. 阿里巴巴达摩院给出的解决方案是`分类预测`，具体做法是给*183个罪名设定了10个attr，每个attr的值有三类：命中、不命中、不确定，每个样本在这10个attr上做三分类的预测*。

## 模型融合问题 ##
模型融合是很多团队都考虑到的方案，`不同模型的融合`，`机器学习模型与深度学习模型的融合`等等。

#  八、总结 #
第一届“中国法研杯---司法人工智能挑战赛”比赛已经圆满落幕，在各个子任务上已经取得了很大的进步，在这次比赛的过程中，也向一些企业、高校学习到了很多宝贵的经验。附上比赛合影。 
 
![](https://i.imgur.com/P6feF3J.jpg)

# References  #
[1]  [中国法研杯---人工智能司法比赛](http://cail.cipsc.org.cn/instruction)   
[2]  [thunlp/CAIL](https://github.com/thunlp/CAIL)    
[3]  [Deep contextualized word representations](https://arxiv.org/pdf/1802.05365.pdf)  
[4] [Few-Shot Charge Prediction with Discriminative Legal Attributes](http://www.aclweb.org/anthology/C18-1041)






  



  
 








