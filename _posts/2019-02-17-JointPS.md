---
layout:     post
title:      "A Simple and Effective Neural Model for Joint Word Segmentation and POS Tagging"
date:       2019-02-17
author:     "bamtercelboo"
header-img: "img/post-bg-2015.jpg"
tags:
    - Joint Model
    - Word Segmentation
    - POS Tagging

---


#  一、导读  #
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这篇文章提出了一个简单有效的`联合模型`，联合学习`中文分词`和`词性标注`，并且在五个数据集上面进行验证。作者是黑龙江大学 --- [张梅山](https://zhangmeishan.github.io/)。  代码开源 --- [c++版本](https://github.com/zhangmeishan/NNTranJSTagger)和[pytorch版本](https://github.com/bamtercelboo/pytorch_Joint-Word-Segmentation-and-POS-Tagging)。

#  二、引言  #
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`中文分词和词性标注`是中文自然语言处理领域的基本问题，目前存在的方法把这两个任务看成结构化学习问题，采用`序列标注模型`或者是`transition-based系统`进行处理。我们知道，中文分词和词性标注两个任务之间存在很高的关联性，而且采用两个任务的Pipline模型存在一定的错误传播，然而，联合模型能够考虑两个任务之间的内在关系并且减少Pipline模型的错误传播，所以联合模型能够达到比Pipline更好的性能。  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这项工作中，提出了一个基于Seq2Seq的联合模型，这个工作主要受张岳在2010年ACL中transition工作的影响，转换解码过程为动作预测过程。另外采用字符级别的unigrams和bigrams特征作为神经网络模型输入。除此之外，还采用多种外部预训练词向量。  

#  三、神经网络模型  #

## 3.1 Transition System ##
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`Transition-based 框架`大多数应用于结构化学习问题，通过预先定义好的transition系统，在解码过程中一步步的进行解码。具体来说，包含两个主要的部分，一个是用于存储部分结果的`当前状态(states)`，另一个则是预测的`动作行为(actions)`。  

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文预先定义好的`transition系统`同样也包含`state`和`action`两个关键部分。其中，`状态(state)`包含`stack`和`queue`两个部分，`stack`用于存储当前的分词和词性标注的结果，`queue`用于保存未处理的中文字符。进一步，定义了`SEP(t)`和`APP`两种不同的`动作行为(action)`，`SEP(t)`代表的是一个新词的`开始`，并且标注好这个词的`词性`，`APP`代表紧接着上一个汉字，与前面的多个汉字组成一个词。本文给出了一个transition系统的案例，给定一个句子：“`奥运会正式开幕`”，能够得到最终的解码结果：“`奥运会|NR 正式|AD 开幕|VV`”，动作序列为“`SEP(NR) APP APP SEP(AD) APP SEP(VV) APP`”。  
![](https://i.imgur.com/OEpjxNS.jpg)  

## 3.2 Seq2Seq Model --- Encoder(编码) ##
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`模型整体结构图如下图所示。`  
![](https://i.imgur.com/UJBIndS.jpg)  

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`Encoder`部分是对句子序列的编码，在这一部分，用到了`单字`和`双字`特征，并且采用了`static`(神经网络训练过程中不更新参数，采用外部预训练词向量)和`non-static`(神经网络模型训练过程中更新参数，采用随机初始化的方式)，图中采用了`不同的颜色`表示，并且利用`非线性层`结合这四种特征，然后采用`BiLSTM`对句子进行编码。  

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在外部预训练词向量的工作中，采用了两种不同的方式进行训练单字和双字的外部词向量，得到的两种预训练词向量分别称之为`Basic Embeddings` 和 `Word-Context Embeddings`，`Basic Embeddings`仅仅采用语言模型的方式预训练词向量(`word2vec`)，`Word-Context Embeddings`不仅仅采用语言模型训练词向量，还考虑了`词的边界信息`以`及词性信息`等来丰富外部预训练的信息，使其更能够辅助联合模型达到更好的效果。


## 3.3 Seq2Seq Model --- Decoder(解码) ##


# References  #
[1]  [A Simple and Effective Neural Model for Joint Word Segmentation and POS Tagging](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8351918&tag=1)   
[2] [bamtercelboo/pytorch_Joint-Word-Segmentation-and-POS-Tagging](https://github.com/bamtercelboo/pytorch_Joint-Word-Segmentation-and-POS-Tagging)  
[3] [zhangmeishan/NNTranJSTagger](https://github.com/zhangmeishan/NNTranJSTagger)  
[4] [bamtercelboo/NNTranJSTagger](https://github.com/bamtercelboo/NNTranJSTagger)  
[5] [A Fast Decoder for Joint Word Segmentation and POS-Tagging Using a Single Discriminative Model](http://aclweb.org/anthology/D10-1082)








  



  
 








